# Gesture-Controlled DJI Model ğŸšâœ‹

This project implements a **gesture-controlled system** to interact with a DJI drone using hand signs.  
It includes three main modules:
1. **Data Collection** â†’ `signDataset.py`
2. **Model Training** â†’ `training.ipynb`
3. **Live Detection** â†’ `liveDetect.py`

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ Gestures/ # Folder containing collected gesture images
â”œâ”€â”€ pycache/ # Python cache files
â”œâ”€â”€ GestureModel.pt # Saved PyTorch model
â”œâ”€â”€ GestureModel.py # Model architecture definition
â”œâ”€â”€ best_gesture_model.pth # Best trained model weights
â”œâ”€â”€ liveDetect.py # Real-time gesture detection & control
â”œâ”€â”€ signDataset.py # Script for gesture dataset collection
â”œâ”€â”€ training.ipynb # Jupyter Notebook for training the model
â”œâ”€â”€ tempCodeRunnerFile.py # Temporary runner file (can be ignored)
â””â”€â”€ README.md # Project documentation

yaml
Copy
Edit

---

## ğŸš€ Features
- **Collect custom gesture datasets** using your webcam.
- **Train deep learning models** for hand sign recognition.
- **Perform real-time detection** and control a DJI drone.

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/Gesture-Controlled-DJI-Model.git
   cd Gesture-Controlled-DJI-Model
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
(Make sure to include packages like torch, opencv-python, numpy, etc.)

Connect your DJI Drone
Ensure your drone SDK/API is properly configured.

ğŸ“Š Workflow
1. Data Collection (signDataset.py)
Run the script to capture hand gesture images from your webcam.

Data is saved in the Gestures/ folder.

bash
Copy
Edit
python signDataset.py
2. Model Training (training.ipynb)
Open the Jupyter Notebook.

Train the model with your collected dataset.

The best model weights are saved as best_gesture_model.pth.

3. Live Gesture Detection (liveDetect.py)
Run the live detection script to recognize gestures in real-time.

The drone responds to recognized hand signs.

bash
Copy
Edit
python liveDetect.py
âœ… Example Gestures
âœŠ Fist â†’ Takeoff

âœ‹ Open Palm â†’ Land

ğŸ‘† Pointing â†’ Move Forward

ğŸ‘‰ Right Gesture â†’ Move Right

ğŸ‘ˆ Left Gesture â†’ Move Left

(Modify gesture mappings as needed in liveDetect.py)

ğŸ“Œ Future Improvements
Add more robust gesture datasets.

Improve accuracy with transfer learning.

Extend support for additional drone commands.

ğŸ“ License
This project is licensed under the MIT License - feel free to use and modify.

ğŸ¤ Contributing
Pull requests are welcome! For major changes, open an issue first to discuss what youâ€™d like to change.
